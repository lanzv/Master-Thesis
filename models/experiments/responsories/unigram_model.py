# -*- coding: utf-8 -*-
"""unigram_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CFkTuErowGNrmTzm59vSnr02bCKKKlmi
"""

import logging
logging.getLogger().setLevel(logging.INFO)

!pip install levenshtein

from src.utils.loader import prepare_dataset
from src.eval.pipelines import evaluation_pipeline
from src.models.unigram_model import UnigramModel

# Get Data
X, y = prepare_dataset()
X_train, y_train = X[:int(0.9*4922)].tolist(), y[:int(0.9*4922)].tolist()
X_dev, y_dev = X[int(0.9*4922):4922].tolist(), y[int(0.9*4922):4922].tolist()
X_test, y_test = X[4922:].tolist(), y[4922:].tolist()
# Init model
model = UnigramModel(1, 7)
# Train and Fit model
model.train(X_train, X_dev, y_train, y_dev, iterations=5, init_mode = "gaussian")
# Predictions
mjwp_score = model.get_mjwp_score()
X_train = X_train+X_dev
y_train = y_train+y_dev
train_segmentation, train_perplexity = model.predict_segments(X_train)
test_segmentation, test_perplexity = model.predict_segments(X_test)

# Evaluate model
bacor_model = evaluation_pipeline(
    train_segmentation, y_train, test_segmentation, y_test, train_perplexity, test_perplexity, mjwp_score,
    max_features_from_model = 100, include_additative = False, fe_occurence_coef=10)

from src.utils.loader import prepare_dataset
from src.eval.pipelines import evaluation_pipeline
from src.models.unigram_model import UnigramModel

# Get Data
X, y = prepare_dataset()
X_train, y_train = X[:int(0.9*4922)].tolist(), y[:int(0.9*4922)].tolist()
X_dev, y_dev = X[int(0.9*4922):4922].tolist(), y[int(0.9*4922):4922].tolist()
X_test, y_test = X[4922:].tolist(), y[4922:].tolist()
# Init model
model = UnigramModel(1, 5)
# Train and Fit model
model.train(X_train, X_dev, y_train, y_dev, iterations=5, init_mode = "gaussian")
# Predictions
mjwp_score = model.get_mjwp_score()
X_train = X_train+X_dev
y_train = y_train+y_dev
train_segmentation, train_perplexity = model.predict_segments(X_train)
test_segmentation, test_perplexity = model.predict_segments(X_test)

# Evaluate model
bacor_model = evaluation_pipeline(
    train_segmentation, y_train, test_segmentation, y_test, train_perplexity, test_perplexity, mjwp_score,
    max_features_from_model = 100, include_additative = False, fe_occurence_coef=10)

from src.utils.loader import prepare_dataset
from src.eval.pipelines import evaluation_pipeline
from src.models.unigram_model import UnigramModel

# Get Data
X, y = prepare_dataset()
X_train, y_train = X[:int(0.9*4922)].tolist(), y[:int(0.9*4922)].tolist()
X_dev, y_dev = X[int(0.9*4922):4922].tolist(), y[int(0.9*4922):4922].tolist()
X_test, y_test = X[4922:].tolist(), y[4922:].tolist()
# Init model
model = UnigramModel(3, 8)
# Train and Fit model
model.train(X_train, X_dev, y_train, y_dev, iterations=5, init_mode = "gaussian")
# Predictions
mjwp_score = model.get_mjwp_score()
X_train = X_train+X_dev
y_train = y_train+y_dev
train_segmentation, train_perplexity = model.predict_segments(X_train)
test_segmentation, test_perplexity = model.predict_segments(X_test)

# Evaluate model
bacor_model = evaluation_pipeline(
    train_segmentation, y_train, test_segmentation, y_test, train_perplexity, test_perplexity, mjwp_score,
    max_features_from_model = 100, include_additative = False, fe_occurence_coef=10)